\section{Experimental Evaluation}

\subsection{Data sets}

To compare the differences in accuracy between the previously discussed methods, we perform a series of experiments based on two data sets which contain circular variables. The first data set, comes from the Orbital Variations and Insolation Database [ref Berger A. and Loutre M.F., 1991. Insolation values for the climate of the last 10 million years. Quaternary Sciences Review, Vol. 10 No. 4, pp. 297-317, 1991.]. It contains data on changes in the earth's orbital parameters, and the resulting variations in insolation. The movements described by these paremeters are commonly known as the Milankovitch cycles [ref. HAYS, J. D., J. IMBRIE, AND N. J. SHAKLETON (1976).  Variations in the Earth's orbit: Pacemaker of the ice ages. Science 194, ll21-1132.]. The second data set contains meteorological data for several airports in Europe. This data set has been assembled combining numerical simulated data from the Global Forecast System model (GFS) \citep{CampanaCaplan2005} and observational data from Meteorological Aerodrome Reports (METAR) \citep{WMO1995}.

These two data sets are used to compare the differences in accuracy and and computational efficiency for the three regression methodologies discussed in this manuscript: linear, circular contiguous and circular non-contiguous trees. Each of these methodologies is used to partition each data set when predicting one of its variables. The errors and the compute times of the different trees are measured at different depths tree to compare their accuracy and computational efficiency.  

\subsection{Experiment Description}

The hypothesis of this study is that our proposed methodology for generating circular regression trees provides better accuracy at any depth level than both the classic linear regression tree and the previous proposal of circular regression trees. Further, since our methodology splits circular variables into contiguous regions, the search space is substantially reduced and the compute times are reduced significantly than Lund's proposal of circular tree. 

In order to prove the previous statement, a general version of regression tree is implemented where each of the input variables can be tagged as \{"linear", "circular"\} and \{"contiguous", "non-contiguous"\}. These two tags indicate the kind of data and split methodology to be applied when computing the tree respectively. Different values of these tags will characterise the different versions of regression trees. 

This tree implementation offers an input parameter called 'maximum leaf size', which is used as the stop criterion to mark the end of the splitting process. Large values of the 'maximum leaf size' produce shallow trees with a few number of partitions and levels. On the other hand, small values of this parameter generate deep trees whith a large number of partitions and levels. To evaluate the differences in accuracy between each methodology, a 5-fold cross validation process is used. The accuracy of a tree is measured by computing the root mean squared error (RMSE) comparing the value of the class variable of a row and the mean of the members contained in the corresponding child node of the tree. To avoid differences in the results caused by considering different partitions during the validation process, the same partition is used to test the three methodologies each time.

Fully grown trees may lose some generalization capabilities, which is also known as overfitting. [Kotsiantis, S Artif Intell Rev (2013) 39: 261.] Comparing the RMSE accuracy levels at different depth or levels of partition provides insight on the quality of the partitions and allows detecting when accuracy starts to degrading. Using the data sets described above, we measure RMSE and CPU time to complete for the different tree versions and for a range of 'maximum leaf size' values.

\subsection{Orbital variations data set}

The Orbital Variations and Insolation Database contains the values of the eccentricity, obliquity and orbital precession of the earth for the last 5 million years. Each of these parameters completes a cycle with a fixed period and the position of the earth at any particular moment is determined by the combination of all three. The earth takes around 41.000 years to complete an obliquity cycle and 26.000 year to complete a precession one. Extracting the angle phases of these two parameters and considering them as circular variables, we try to predict the values of solar radiance at 65 degrees north of latitude in July, parameter also contained in the data set.

The whole data set contains around 3300 !!!!MAKE IT 3300!!! and the 'maximum leaf size' values of 2500, 1250, 500 and 250 are used to generate different versions of each tree.  rows and a 5-fold cross validation is used to predict solar radiance values at different depths of the tree. 

\begin{table*}[t]
\caption{RMSE in predicting the observed METAR wind speed and CPU time for the different airports using the different versions of regression trees.}\label{t4}
\begin{center}
\begin{tabular}{ccrrrrrr}
\hline\hline
$Airport$ & $Tree\ Version$ & \multicolumn{6}{|c|}{Max Leaf Size}\\
$$ & $$ & \multicolumn{2}{|c|}{2500} & \multicolumn{2}{|c|}{1250} & \multicolumn{2}{|c|}{500} & \multicolumn{2}{|c|}{250}\\
$$ & $$ & $RMSE$ & $CPU(s)$ & $RMSE$ & $CPU(s)$ & $RMSE$ & $CPU(s) & $RMSE$ & $CPU(s) $\\
\hline
65°N Radiation & Linear & 0.913 & 16 & 0.833 & 27 & 0.357 & 39 & 0.220 & 39\\
65°N Radiation & Proposed & 0.620 & 23 & 0.372 & 36 & 0.233 & 53 & 0.216 & 39\\
65°N Radiation & Lund's & 0.620 & 34 & 0.389 & 50 & 0.3577 & 71 & 0.340 & 39\\
\hline
\end{tabular}
\end{center}
\end{table*}
 
\begin{table*}[t]
\caption{Tagged input variables for the different versions of regression trees.}\label{t3}
\begin{center}
\begin{tabular}{llllll}
\hline\hline
$Name$ & \multicolumn{4}{c}{Input Variables} \\ \hline
 & $Precession$ & $Obliquity$ \\
\hline
Linear Contiguous & lin, con & lin, con\\
Circular Contiguous & cir, con & cir, con\\
Circular Non-Contiguous & cir, non-con & cir, non-con\\
\hline
\end{tabular}
\end{center}
\end{table*}


\subsection{Airports meteorology data set}

\begin{table*}[t]
\caption{Tagged input variables for the different versions of regression trees.}\label{t3}
\begin{center}
\begin{tabular}{llllll}
\hline\hline
$Name$ & \multicolumn{4}{c}{Input Variables} \\ \hline
 & $Date$ & $Time$ & $GFS\ RH$ & $GFS\ Wind\ speed $\\
\hline
Linear Contiguous & lin, con & lin, con & lin, con & lin, con\\
Circular Contiguous & cir, con & cir, con & lin, con & lin, con\\
Circular Non-Contiguous & cir, non-con & cir, non-con & lin, con & lin, con\\
\hline
\end{tabular}
\end{center}
\end{table*}

Combining the data from GFS and METARs, seven data sets are produced, containing different forecasted and observed weather variables for the airports of London Heathrow (EGLL), Berlin Tegel (EDDT), Barcelona El Prat (LEBL), Paris Charles de Gaulle (LFPG), Milano Malpensa (LIMC), Beijing International Airport (ZBAA) and Sydney Kingsford Smith (YSSY). Three hourly data is collected for the years 2011, 2012 and 2013, giving approximately 8760 samples per airport. The variables contained in these data sets are: 2 metres temperature from the METAR reports and 2 metres relative humidity, 10 metres wind speed from the GFS numerical model. Every row in the data set has a timestamp describing the date and the time of the values. Table \ref{t2} contains a sample of the airport of Sydney (YSSY) data set.

\begin{table}[t]
\caption{Sample of the time series data for the airport of Sydney (YSSY) combining data from the GFS model and METARs.}\label{t2}
\begin{center}
\begin{tabular}{crrrrrr}
\hline\hline
$Date$ & $Time$ & $GFS\ rh$ & $GFS\ w\_spd$ & $METAR\ t$\\
\hline
2012-03-09 & 00:00 & 54.6 & 3.33 & 23.0\\
2012-03-09 & 03:00 & 42.3 & 3.34 & 25.0\\
2012-03-09 & 06:00 & 49.9 & 3.77 & 25.0\\
2012-03-09 & 09:00 & 79.3 & 1.30 & 21.0\\
2012-03-09 & 12:00 & 80.7 & 2.34 & 20.0\\
2012-03-09 & 15:00 & 88.2 & 1.43 & 19.0\\
\hline
\end{tabular}
\end{center}
\end{table}

The variables Date and Time are transformed into their angular numerical values so that they can be used in a regression tree. These two variables can be considered as circular variables in the circular versions of the regression tree.

Using statistical methods to improve numerical weather models accuracy based on observational data is a common practice and represents an active area of research \citep{Larraondoetal2014, Salamehetal2009}. The proposed methodology can be applied to any data set containing circular variables. Weather models usually contain many parameters represented as circular variables, which makes them ideal to test these methods.

\subsection{Experiment Description}

The hypothesis of this study is that our proposed methodology for generating circular regression trees provides better computational efficiency and accuracy than the previous proposal of circular regression trees. Further, since this methodology allows circular variables to be split at any region of the space, it can provide more accurate results than the classic linear regression tree.

In order to prove the previous statement, a general version of regression tree is implemented where each of the input variables can be tagged as \{"linear", "circular"\} and \{"contiguous", "non-contiguous"\}. These two tags indicate the kind of data and split methodology to be applied when computing the tree respectively. Different values of these tags will indicate different versions of regression trees.

A set of experiments is carried out to compare the computational efficiency and accuracy of these three versions of regression trees. Using the data sets described above, observed METAR temperature is considered as the target variable and the rest of the variables are the input variables. The classical linear version considers all the input variables to be linear. The circular versions consider Date and Time as circular variables and the rest of the input variables as linear. Table \ref{t3} represents the tags that each input variable receives for each version of the tree: classic linear regression, our proposed methodology based on contiguous circular splits and Lund's proposal of non-contiguous circular splits.


The stop criterium for all trees is based on the number of elements in a node. Splits are recursively performed until the number of data entries in a node falls below a certain value. Then, the splitting process is stopped and the node is denoted as leaf. This value receives the name of ”maximum leaf size”. Large values of ”maximum leaf size” generate shallow trees, whereas small values will generate deep trees. Each version of the considered trees is evaluated using three maximum leaf sizes: 250, 100 and 50.

To evaluate the differences in accuracy between each of these tree methodologies, a 5-fold cross validation procedure is used. The cross validation process splits the data into five sub-samples. One of the sub-samples, each time, is used to validate the results of the tree trained using the content of the remaining four sub-samples: these two groups are called test and training sub-samples, respectively. To avoid differences in the results caused by different partitions in the validation process, the same partition is used to validate the three methodologies for the different values of the ”maximum leaf size” parameter.

The error in forecasting a single value is defined as the difference between the temperature predicted by the tree, which is the mean of the target values contained in the selected leaf, and the observed METAR temperature value. At the end of the cross validation process, the Root Mean Square Error (RMSE) is calculated for each tree and airport.


\subsection{Experimental Results}
\label{sec:4.3}

The current section contains the results of the experiments described in the previous section.
It is worth mentioning that execution times are highly dependent on the architecture of the computer executing the code. The CPU times represented in Table \ref{t4} correspond to a desktop with a 3.2 GHz Intel Core i3 processor. The ratios between CPU times for the different experiments should be in the same order, regardless of the execution environment.

Table \ref{t4} shows the accuracy, measured using RMSE, and the efficiency, measured in CPU seconds, for the different trees, leaf sizes and airports. The accuracy results can be better interpreted when represented as a series of plots.

Figure \ref{f6} contains a graphical representation of the RMSE values of the different experiments. Looking at the plots it can be observed that the best accuracy for every airport is achieved by the proposed version of circular tree. To statistically compare the results of the different algorithms each leaf size is considered as a different experiment which needs to be validated independently. For each leaf size we have the RMSE values for the seven airports and three methodologies. A non-parametric Friedman test is used to control the variability between methodologies. For each leaf size, the methodology proposed by \citep{Demsar2006} is used to assess the statistical significance of the differences between compared algorithms. The null hypothesis of similarity is rejected for each leaf size; this justifies the use of post-hoc bivariate tests (Nemenyi test, in our case), which assess the statistical difference between pairs of algorithms. The results of this test can be graphically expressed using Critical Difference (CD) diagrams.

\begin{table*}[t]
\caption{RMSE in predicting the observed METAR wind speed and CPU time for the different airports using the different versions of regression trees.}\label{t4}
\begin{center}
\begin{tabular}{ccrrrrrr}
\hline\hline
$Airport$ & $Tree\ Version$ & \multicolumn{6}{|c|}{Max Leaf Size}\\
$$ & $$ & \multicolumn{2}{|c|}{50} & \multicolumn{2}{|c|}{100} & \multicolumn{2}{|c|}{250}\\
$$ & $$ & $RMSE$ & $CPU(s)$ & $RMSE$ & $CPU(s)$ & $RMSE$ & $CPU(s)$\\
\hline
EDDT & Linear  & 3.844 & 16 & 3.868 & 27 & 4.013 & 39\\
EDDT & Proposed & 3.822 & 23 & 3.854 & 36 & 3.981 & 53\\
EDDT & Lund's & 3.994 & 34 & 3.989 & 50 & 4.055 & 71\\
\hline
EGLL & Linear  & 3.094 & 15 & 3.147 & 24 & 3.257 & 35\\
EGLL & Proposed  & 3.053 & 22 & 3.083 & 35 & 3.241 &50\\
EGLL & Lund's & 3.260 & 33 & 3.227 & 48 & 3.250 & 65\\
\hline
YSSY & Linear  & 2.634 & 16 & 2.625 & 22 & 2.670 & 29\\
YSSY & Proposed  & 2.613 & 21 & 2.601 & 30 & 2.680 & 39\\
YSSY & Lund's & 2.743 & 36 & 2.699 & 50 & 2.727 & 62\\
\hline
ZBAA & Linear  & 3.493 & 20 & 3.540 & 34 & 3.841 & 55\\
ZBAA & Proposed  & 3.354 & 26 & 3.374 & 44 & 3.524 & 64\\
ZBAA & Lund's & 3.843 & 32 & 3.851 & 54 & 3.864 & 80\\
\hline
LEBL & Linear  & 2.234 & 18 & 2.264 & 30 & 2.345 & 36\\
LEBL & Proposed  & 2.202 & 25 & 2.232 & 41 & 2.316 & 52\\
LEBL & Lund's & 2.561 & 31 & 2.525 & 46 & 2.521 & 61\\
\hline
LFPG & Linear  & 3.586 & 17 & 3.595 & 27 & 3.699 & 39\\
LFPG & Proposed  & 3.545 & 24 & 3.567 & 38 & 3.691 & 54\\
LFPG & Lund's & 3.843 & 33 & 3.794 & 48 & 3.766 & 63\\
\hline
LIMC & Linear  & 3.753 & 18 & 3.779 & 29 & 3.898 & 43\\
LIMC & Proposed  & 3.883 & 24 & 3.749 & 39 & 3.765 & 58\\
LIMC & Lund's & 3.865 & 30 & 3.819 & 48 & 3.848 & 66\\
\hline
\end{tabular}
\end{center}
\end{table*}

\begin{figure*}
  %%\includegraphics[width=8cm]{berlin.png}
  %%\includegraphics[width=8cm]{heathrow.png}
  \includegraphics[width=8cm]{sydney.png}
  %%\includegraphics[width=8cm]{beijing.png}
  \includegraphics[width=8cm]{barcelona.png}
  %%\includegraphics[width=8cm]{charles.png}
  %%\includegraphics[width=8cm]{milano.png}
\caption{RMSE values for the airports of Sydney and Barcelona comparing the accuracy of regression trees for different maximum leaf sizes.}
\label{f6}
\end{figure*}

The Nemenyi test pairwise compares every methodology. The accuracy of two methodologies is significantly different if the corresponding average rank differs by at least the critical difference. Figure \ref{f7} contains a representation of the results of the Nemenyi test comparing RMSE results for the three methodologies, one test per leaf size. These tests have been performed using the \textit{scmamp} R package publicly available at the Comprehensive R Archive Network (CRAN) \citep{Calvo2015}. Figure \ref{f7} represents the results of this test for a significance level $ p < 0.05 $ making use of CD diagrams.  These diagrams connect the groups of algorithms that are not significantly different, or in other words, whose distance is less than the critical difference, shown above the graph. As can be seen in the diagrams shown in Figure \ref{f7}, the proposed methodology outperforms the other two. Note that higher ranked algorithms in CD diagrams implies lower RMSE values.

\begin{figure}
\centering
\parbox{5cm}{
\includegraphics[width=6cm]{CD.pdf}}
\qquad
\caption{Critical Difference figures comparing the three methodologies for the different leave sizes.}
\label{f7}
\end{figure}

One of the most significant aspects of these results is the different evolution, for each compared method, for the different maximum leaf sizes considered. For most of the airports, both the classic linear and the proposed methodologies improve their accuracy as the maximum leaf size is reduced. On the other hand, Lund's method presents no difference or degrades as the leaf size is reduced. This is a sign of poor generalisation of the splits lower down in the tree. Tests to detect the nature of this problem show that the error at training time also increases for this data set. This suggests that the use of non-contiguous splits for circular variables do not provide a good generalisation for subsequent splits performed by the tree.

Table \ref{t4} also reflects the differences in computational time for the different versions of the considered trees and leaf sizes. The proposed circular regression tree methodology offers a substantial reduction in computational efficiency when compared to Lund's proposal. It is relevant to mention that the differences in efficiency between the different versions is highly dependent on the data set. The main improvement in our methodology when compared to the previous circular trees is that once a circular variable has been selected to create a split in a node, all subsequent splits will traverse that variable in linear time instead of quadratic. The sooner circular variables are used to generate splits in a tree the more efficient it will be. Data sets containing circular variables which are poorly correlated to the target variable will cause long computations, as they will not be used to create splits at any node of the tree. 
